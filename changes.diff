diff --git a/.gitignore b/.gitignore
index af71b8b..425d826 100644
--- a/.gitignore
+++ b/.gitignore
@@ -73,3 +73,6 @@ coverage.xml
 # Mac / Linux / Windows junk
 .DS_Store
 Thumbs.db
+
+
+FDM_MLB_G07.pdf
\ No newline at end of file
diff --git a/Docs/FDM - IT3051- Mini Project - 2025 - finalized instructions.pdf b/Docs/FDM - IT3051- Mini Project - 2025 - finalized instructions.pdf
new file mode 100644
index 0000000..f372dab
--- /dev/null
+++ b/Docs/FDM - IT3051- Mini Project - 2025 - finalized instructions.pdf	
@@ -0,0 +1,58 @@
+                         Fundamentals of Data Mining
+                                    Data Science
+
+                              Faculty of Computing
+               Sri Lanka Institute of Information Technology
+
+                                          FDM Mini Project - 2025
+Due date: 6th of October, 12.00 am
+
+Type: Group work (4 members)
+
+Deliverables:
+
+-  SOW, Final Report, Software solution, 10 min video presentation
+
+Evaluation: Based on demonstration, viva, and reports
+
+Weight for the final grade: 25 %
+
+Step 1
+Register your project with the given link on the subject page on or before the 22nd of August.
+
+Step 2
+Find out a real-world problem (use publicly available datasets) and propose solutions using
+Data Mining / Machine Learning techniques.
+
+Before working on the project, make sure to show the datasets that you have selected to your lab
+instructor/lecturer by the next week (week starting from 25th August), to get the approval to
+
+continue your project during your allocated lab sessions. Please get the finalized decision for
+the dataset selection at least by the 7th of September.
+
+After getting the approval for the topic and dataset, the team should submit the statement of work
+(SOW) document. It should include the following,
+
+        Background
+        Scope of work
+        Activities
+        Approach
+        Deliverables
+        Project Plan & Timeline
+        Assumptions
+        Project team, roles, and responsibilities
+
+Step 3
+Plan for final submission as described above.
+
+    When selecting datasets, ensure that they comprise at least 10,000 rows with recent data
+       and can be applied with preprocessing. It is recommended to identify backup datasets to
+       mitigate any risks with your primary data source.
+As per instructions, you are free to use any technology for building your application. Since you
+are building a product for a real world problem, aiming for customer satisfaction, you can
+customize your product accordingly with the technologies you have used.
+
+The final viva evaluations will commence in the week starting from the 6th of October. The
+team leader should submit the final report, video, and the necessary source codes using
+notebooks by the 6th of October.
+
diff --git a/Docs/FDM Mini Project-marking grid.pdf b/Docs/FDM Mini Project-marking grid.pdf
new file mode 100644
index 0000000..6671a24
--- /dev/null
+++ b/Docs/FDM Mini Project-marking grid.pdf	
@@ -0,0 +1,41 @@
+                                   20%-                         40%-             50%-             60%-69% 70%-79%                                 80%-89%                 90%-100%                      Marks
+                    0%-19% 39%                                  49%              59%
+                                                                                                                                                  Bussiness goals     All the requirements set in
+                               Missing or     Many              Some incorrect   Most important   Bussiness goals      Bussiness goals and        and funtionalities  the range
+                               demonstrates   important         interpretations  points of the    and funtionalities   funtionalities have        have identified     (80-89) satisfied plus provision
+                               little or no   points missing    coresponds to    scenario has     have identified but  identified and             and explanation in  of alternative solutions with
+                               understanding                    the              considerd.       no clear             explanation in detail.     detail.             appropriate explanation for the
+                                              or poorly         requirements of                   explanation          Justification of model     Justification       provision of these solutions.
+1. Problem                                                      the given                                              compared with              include.            This range of grades shows
+definition Business                           described.        scenario                                               alternatives from the                          that the student examined the
+goals Data mining                                                                                                      Individual Assignment.                         tasks in a more-in-depth
+functionality :                                                                                                                                                       manner and provided more
+20%]                                                                                                                                                                  work than what
+                                                                                                                                                                      the assignment was asking for.
+                                                                                                                                                                      A fully perfect documentation.
+
+                    Missing or                Many              Some             Most important   Even more            Very well planed           Perfect use of      All the requirements set in
+                    demonstrates              important         important        methods have     important            techniqes and methods      techniques and      the range
+                    little or no              points missing    methods          applyied with    methods have         have applyied. Very        methods.            (80-89) satisfied plus provision
+                    understanding             or poorly         applyied. Some   minor corrects.  applyied with        good.                      Justifications are  of alternative solutions with
+                                              described.        correct use of                    minor corrects.      Justification include.     presented.          appropriate explanation for the
+2.Data selection,                             Incorrect use of  them.                             .more sensible                                                      provision of these solutions.
+preparation, and                              some                                                and adequate                                    Alternative         This range of grades shows
+preprocessing.                                techniques.                                         methods shown.                                  techiniques         that the student examined the
+[Weight: 20%]                                                                                                                                                         tasks in a more-in-depth
+                                                                                                                                                  discussed.          manner and provided more
+                                                                                                                                                                      work than what the
+                    Missing or                Some attempt,     Implementation   Implemented a    Implemented a        Very well planed and       Perfect solution.   assignment was asking for.
+                    demonstrates              but badly         of a basic       model, and       model and            implemented model          Has fine-tuned.     All the requirements set in
+                    little or no              flawed.           model, and       received some    finetuned it to      and fine-tuned it to take  Justifications are  the range
+                                                                some results.    results and      take good results    good results and           presented.          (80-89) satisfied plus provision
+                    understanding.                              No clear         explanation      and explanation      explanation them           Alternative         of alternative solutions with
+                                                                explanation.     them.            them clearly         clearly including          techiniques         appropriate explanation for the
+3. Building and                                                                                                        justifications.            discussed.          provision of these solutions.
+evaluating models.                                                                                                                                                    This range of grades shows
+[20%]                                                                                                                                                                 that the student examined the
+                                                                                                                                                                      tasks in a more-in-depth
+                                                                                                                                                                      manner and provided more
+                                                                                                                                                                      work than what the
+                                                                                                                                                                      assignment was asking for.
+
diff --git a/Docs/Final submission guidelines.pdf b/Docs/Final submission guidelines.pdf
new file mode 100644
index 0000000..bba7fbc
--- /dev/null
+++ b/Docs/Final submission guidelines.pdf	
@@ -0,0 +1,53 @@
+FDM Mini Project 2025
+
+Final submission
+
+Final Report, Software solution, 10-minute video presentation, source code
+
+1.Final report
+
+Please refer to the report template. Report’s cover page should contain the video link, repository
+link (Ex: Github repo link which contains all the work of the project, including front end and back
+end work), and the software application’s deployment link. The final report should include
+comprehensive documentation of the work carried out during the project. Images can be used
+to support the work as applicable.
+
+2.Video submission guidelines
+
+For the video creation, all members can take part in presenting background, business goals, usage
+of tools and technologies for implementation in brief (not necessarily code), challenges faced,
+and solutions for them, further implementation, and demonstration of your software solution.
+Hence, the video should mostly focus on the demonstration of your working software.
+
+• As per instructions, you are free to use any technology for building your application. Since you
+are building a product for a real world problem, aiming for customer satisfaction, you can
+customize your product accordingly with the technologies you have used.
+
+3.Source code submission
+
+Students should upload only source code, excluding libraries for the project base. A .py file that
+includes all the code necessary to support all the team’s work can be submitted to the submission
+link.
+
+The final submission folder should therefore have the final report, source code/s in .py format,
+and the video presentation.
+
+During the viva, your submission folders will be used; therefore, there can be no changes made
+after the deadline (6th of October, 12.00 am) that are to be presented during final evaluations.
+
+Therefore, the submission folder should have the final report, source code/s, and video
+presentation. A submission for each team can be made by renaming the folder,
+
+<Batch_sub_group_leader ’s_IT_number> (ex: Y3.S1.DS.01.01_IT23XXXXX) for easy
+identification.
+Viva session
+
+The final viva will be conducted as usual, individually from each member, to test understanding
+of the project's steps. You should have a proper understanding of the whole project, according
+to the techniques you have used, be it data mining/machine learning, etc.
+
+Each member should have an in-depth idea and understanding on the dataset, data
+preprocessing steps, data transformation, model selection and development, backend and
+frontend integration, front end development and the final deployment of the complete software
+solution with necessary refinements and integrations.
+
diff --git a/Docs/Markdown/FDM - IT3051- Mini Project - 2025 - finalized instructions.md b/Docs/Markdown/FDM - IT3051- Mini Project - 2025 - finalized instructions.md
new file mode 100644
index 0000000..ad27211
--- /dev/null
+++ b/Docs/Markdown/FDM - IT3051- Mini Project - 2025 - finalized instructions.md	
@@ -0,0 +1,48 @@
+**Fundamentals of Data Mining**
+**Data Science**
+**Faculty of Computing**
+**Sri Lanka Institute of Information Technology**
+
+---
+
+**FDM Mini Project - 2025**
+
+**Due date:** 6th of October, 12.00 am
+
+**Type:** Group work (4 members)
+
+**Deliverables:**
+- SOW, Final Report, Software solution, 10 min video presentation
+
+**Evaluation:** Based on demonstration, viva, and reports
+
+**Weight for the final grade:** 25 %
+
+**Step 1**
+Register your project with the given link on the subject page on or before the 22nd of August.
+
+**Step 2**
+Find out a real-world problem (use publicly available datasets) and propose solutions using Data Mining / Machine Learning techniques.
+
+Before working on the project, make sure to show the datasets that you have selected to your lab instructor/lecturer by the next week (week starting from 25th August), to get the approval to continue your project during your allocated lab sessions. Please get the finalized decision for the dataset selection at least by the 7th of September.
+
+After getting the approval for the topic and dataset, the team should submit the statement of work (SOW) document. It should include the following,
+- Background
+- Scope of work
+- Activities
+- Approach
+- Deliverables
+- Project Plan & Timeline
+- Assumptions
+- Project team, roles, and responsibilities
+
+**Step 3**
+Plan for final submission as described above.
+
+*   When selecting datasets, ensure that they comprise at least **10,000 rows** with recent data and can be applied with **preprocessing**. It is recommended to identify backup datasets to mitigate any risks with your primary data source.
+
+---
+
+As per instructions, you are free to use any technology for building your application. Since you are building a product for a real world problem, aiming for customer satisfaction, you can customize your product accordingly with the technologies you have used.
+
+The final viva evaluations will commence in the week starting from the 6th of October. The team leader should submit the final report, video, and the necessary source codes using notebooks by the 6th of October.
\ No newline at end of file
diff --git a/Docs/Markdown/FDM Mini Project-marking grid.md b/Docs/Markdown/FDM Mini Project-marking grid.md
new file mode 100644
index 0000000..edbf6d2
--- /dev/null
+++ b/Docs/Markdown/FDM Mini Project-marking grid.md	
@@ -0,0 +1,9 @@
+| | 0%-19% | 20%-39% | 40%-49% | 50%-59% | 60%-69% | 70%-79% | 80%-89% | 90%-100% | Marks |
+| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
+| **1. Problem definition Business goals Data mining functionality : [20%]** | Missing or demonstrates little or no understanding | Many important points missing or poorly described. | Some incorrect interpretations coresponds to the requirements of the given scenario | Most important points of the scenario has considerd. | Bussiness goals and funtionalities have identified but no clear explanation | Bussiness goals and funtionalities have identified and explanation in detail. Justification of model compared with alternatives from the Individual Assignment. | Bussiness goals and funtionalities have identified and explanation in detail. Justification include. | All the requirements set in the range (80-89) satisfied plus provision of alternative solutions with appropriate explanation for the provision of these solutions. This range of grades shows that the student examined the tasks in a more-in-depth manner and provided more work than what the assignment was asking for. A fully perfect documentation. | |
+| **2.Data selection, preparation, and preprocessing. [Weight: 20%]** | Missing or demonstrates little or no understanding | Many important points missing or poorly described. Incorrect use of some techniques. | Some important methods applyied. Some correct use of them. | Most important methods have applyied with minor corrects. | Even more important methods have applyied with minor corrects. .more sensible and adequate methods shown. | Very well planed techniqes and methods have applyied. Very good. Justification include. | Perfect use of techniques and methods. Justifications are presented. Alternative techiniques discussed. | All the requirements set in the range (80-89) satisfied plus provision of alternative solutions with appropriate explanation for the provision of these solutions. This range of grades shows that the student examined the tasks in a more-in-depth manner and provided more work than what the assignment was asking for. | |
+| **3. Building and evaluating models. [20%]** | Missing or demonstrates little or no understanding. | Some attempt, but badly flawed. | Implementation of a basic model, and some results. No clear explanation. | Implemented a model, and received some results and explanation them. | Implemented a model and finetuned it to take good results and explanation them clearly | Very well planed and implemented model and fine-tuned it to take good results and explanation them clearly including justifications. | Perfect solution. Has fine-tuned. Justifications are presented. Alternative techiniques discussed. | All the requirements set in the range (80-89) satisfied plus provision of alternative solutions with appropriate explanation for the provision of these solutions. This range of grades shows that the student examined the tasks in a more-in-depth manner and provided more work than what the assignment was asking for. | |
+| **4. Deploying product. Provide a suitable client App [20%]** | Missing or demonstrates little or no understanding. | Some attempt, but badly flawed. | Implementation of a basic user interface, or a more comprehensive solution which may be notionally or semantically flawed. | Demonstrates a clear understanding of interface principles. May be some errors of application. | Demonstrates a comprehensive understanding. A correct solution within stated constraints which closely models the problem domain. | Demonstrates full understanding. A correct solution within stated constraints which models the problem domain. | A 'perfect' set of Interfaces demonstrating will full accuracy the data flow of the system. | All the requirements set in the range (80-89) satisfied plus provision of alternative solutions with appropriate explanation for the provision of these solutions. This range of grades shows that the student examined the tasks in a more-in-depth manner and provided more work than what the assignment was asking for. | |
+| **5. Provide a documented explanation of your results and demostration. [20%]** | Missing or demonstrates little or no understanding. | Very basic documentation with presentation of few arguments that are not though elaborated properly. | A basic documentation in which there is presentation of few arguments with some basic elaboration of them. | A more comprehensive basic documentation in which there is presentation of more arguments than in the basic documentation (40-49) and more comprehensive basic elaboration of these arguments. | Clear arguments in the documentation presented. Maybe some errors in syntax and language. | A comprehensive documentation which closely approaches perfection. | A 'perfect' solution with all the necessary features. | All the requirements set in the range (80-89) satisfied plus provision of alternative solutions with appropriate explanation for the provision of these solutions. This range of grades shows that the student examined the tasks in a more-in-depth manner and provided more work than what the assignment was asking for. | |
+
+### Comments
\ No newline at end of file
diff --git a/Docs/Markdown/Final submission guidelines.md b/Docs/Markdown/Final submission guidelines.md
new file mode 100644
index 0000000..f83069e
--- /dev/null
+++ b/Docs/Markdown/Final submission guidelines.md	
@@ -0,0 +1,33 @@
+FDM Mini Project 2025
+
+Final submission
+
+Final Report, Software solution, 10-minute video presentation, source code
+
+**1.Final report**
+
+Please refer to the report template. Report's cover page should contain the video link, repository link (Ex: Github repo link which contains all the work of the project, including front end and back end work), and the software application's deployment link. The final report should include comprehensive documentation of the work carried out during the project. Images can be used to support the work as applicable.
+
+**2.Video submission guidelines**
+
+For the video creation, all members can take part in presenting background, business goals, usage of tools and technologies for implementation in brief (not necessarily code), challenges faced, and solutions for them, further implementation, and demonstration of your software solution. Hence, the video should mostly focus on the demonstration of your working software.
+
+* As per instructions, you are free to use any technology for building your application. Since you are building a product for a real world problem, aiming for customer satisfaction, you can customize your product accordingly with the technologies you have used.
+
+**3.Source code submission**
+
+Students should upload only source code, excluding libraries for the project base. A .py file that includes all the code necessary to support all the team's work can be submitted to the submission link.
+
+The final submission folder should therefore have the final report, source code/s in .py format, and the video presentation.
+
+During the viva, your submission folders will be used; therefore, there can be no changes made after the deadline (6th of October, 12.00 am) that are to be presented during final evaluations.
+
+Therefore, the submission folder should have the final report, source code/s, and video presentation. A submission for each team can be made by renaming the folder,
+
+`<Batch_sub_group_leader 's_IT_number> (ex: Y3.S1.DS.01.01_IT23XXXXX)` for easy identification.
+
+**Viva session**
+
+The final viva will be conducted as usual, individually from each member, to test understanding of the project's steps. You should have a proper understanding of the whole project, according to the techniques you have used, be it data mining/machine learning, etc.
+
+Each member should have an in-depth idea and understanding on the dataset, data preprocessing steps, data transformation, model selection and development, backend and frontend integration, front end development and the final deployment of the complete software solution with necessary refinements and integrations.
\ No newline at end of file
diff --git a/Docs/Markdown/scope of work.md b/Docs/Markdown/scope of work.md
new file mode 100644
index 0000000..677b41c
--- /dev/null
+++ b/Docs/Markdown/scope of work.md	
@@ -0,0 +1,240 @@
+# Sri Lanka Institute of information Technology
+## Fundamentals of Data Mining IT3051
+
+### Mini-Project: Statement of Work Document
+**2025**
+
+**Weekend - 2.01: FDM_MLB_G07**
+
+---
+
+### Group Details
+
+| IT Number  | Name              | Email                       | Contact Number |
+| :--------- | :---------------- | :-------------------------- | :------------- |
+| **IT23288744** | **Chamuditha H.V.C** | **it23288744@my.sliit.lk**  | **071 4366463**  |
+| IT23291782 | Hariswara S       | it23291782@my.sliit.lk      | 0775577588     |
+| IT23385900 | Ranasinghe I V L  | it23385900@my.sliit.lk      | 077 129 7010   |
+| IT23232990 | Thennakoon S S H  | it23232990@my.sliit.lk      | 078 642 1227   |
+
+**Submitted On: 2025-09-21**
+
+---
+
+## Table Of content
+- **BACKGROUND** 3
+- **SCOPE OF WORK** 5
+- **ACTIVITIES** 6
+- **APPROACH** 7
+- **DELIVERABLES** 9
+- **ASSUMPTIONS** 10
+- **PROJECT PLAN & TIMELINE** 11
+- **PROJECT TEAM, ROLES AND RESPONSIBILITIES** 12
+
+---
+
+## Background
+
+In the highly competitive landscape of New York City, the transition to data-driven decision-making has become critical for the survival and success of the traditional taxi industry. While ride-hailing services have long utilized predictive analytics, individual taxi drivers are often left to navigate the city's complexities using only intuition and experience. This reliance on conventional methods in a digitally transformed sector creates a significant operational disadvantage.
+
+The NYC Taxi & Limousine Commission (TLC) provides a massive, publicly available dataset containing millions of trip records.
+
+This data holds the key to unlocking profound insights into traffic patterns, fare structures, and passenger behavior. However, for an individual driver or even the Taxi Union, this raw data is an untapped and inaccessible resource, leaving drivers to guess which routes are most profitable or when to anticipate a surge in demand. Conventional fare models, based simply on time and distance, fail to account for the complex variables—like time of day, passenger count, or specific locations—that truly influence a trip's profitability.
+
+Predictive modeling offers a modern solution to this challenge. By applying machine learning algorithms to historical trip data, it is possible to uncover the hidden patterns that dictate fare amounts and tipping habits. This project will harness these techniques to build a system that translates vast, complex data into simple, actionable intelligence. By accurately forecasting fares and identifying the factors that lead to higher tips, we can provide drivers with a tool to move beyond guesswork and make strategic, data-informed decisions.
+
+*   **Problem:** NYC taxi drivers face inconsistent earnings and operational inefficiencies because they lack access to data-driven insights. Traditional fare structures do not account for the many real-world variables that affect trip revenue, making it difficult for drivers to accurately predict their income and optimize their work strategies.
+*   **Client:** The NYC Taxi Drivers' Union, representing independent yellow-cab drivers who face intense competition from large ride-hailing corporations (e.g., Uber, Lyft) whose advanced algorithms optimize pricing, routing, and driver incentives. To remain competitive and increase daily earnings, the union seeks data-driven tools and actionable insights that empower its members to make smarter decisions on pricing, location targeting, and time-of-day operations.
+*   **Solution:** To develop a taxi trip prediction system that uses data mining and machine learning to accurately forecast fare amounts and the likelihood of high tips. By analyzing key trip-related factors, the system will provide drivers with the predictive insights needed to make more profitable decisions.
+*   **Goal:** To create a reliable machine learning model and an interactive tool that can accurately forecast taxi fares and tipping behavior. The ultimate objective is to empower individual drivers with data-driven recommendations, helping them to optimize routes, manage their time effectively, and ultimately increase their profitability and service quality.
+*   **Dataset (Selected and Approved):** We have chosen to construct a NYC Taxi Trip Dataset, which has over 100,000 trip data and is openly accessible, for this research. Time stamps, passenger counts, journey distances, fare amounts, tip amounts, payment methods, and pickup and drop-off locations are among the features included in the dataset. A solid basis for developing predictive models for fare prediction and tipping behavior is provided by this extensive dataset.
+
+---
+
+## Scope of Work
+
+This project is focused on delivering a comprehensive data analysis and a prototype software solution based on a curated static **NYC Yellow Taxi Trip Data**. The scope is defined by the following boundaries to ensure timely and successful completion of the project objectives.
+
+**The following activities are considered IN SCOPE for this project.**
+
+1.  **Dataset Sourcing and Curation**
+    *   Source raw monthly data files for the last three years (2023 – 2025/7) from nyc.gov.
+    *   implement a stratified random-sampling strategy to combine these files into a single, manageable, and representative dataset.
+    *   Target dataset size: approximately 100,000 rows.
+
+2.  **Data Processing**
+    *   Data preparation for the curated dataset, including cleaning, outlier treatment, and feature engineering (e.g., inflation adjustment for prices).
+
+3.  **Exploratory Data Analysis**
+    *   A comprehensive analysis focusing on temporal, geospatial, and financial patterns.
+
+4.  **Predictive Modeling**
+    *   The development and evaluation of two machine learning models:
+        1.  Regression model for fare prediction.
+        2.  Classification model for high-tip prediction.
+
+5.  **Software Solution**
+    *   The creation of a prototype web-based dashboard that includes EDA visualizations and an interactive prediction interface.
+
+**Out of Scope**
+
+1.  **Analysis of the Entire Multi-Year Dataset**
+    *   The entire 3 year / ~33-month Dataset will contain Approx. 100 million rows.
+    *   The analysis will be confined to the curated ~100,000 row sample, not the complete multi-million row dataset.
+
+2.  **Real-Time System** - The project will not process live taxi data.
+
+3.  **Cloud Deployment** - The solution will be developed to run locally.
+
+---
+
+## Activities
+
+1.  **Dataset Sourcing, Curation, and Approval**
+    *   Download the monthly NYC Yellow Taxi data files for the last three years from the official nyc.gov source.
+    *   Develop and execute a Python script to perform stratified random sampling from these files to construct a representative master dataset of ~100,000 records.
+    *   Formally submit the curated dataset and the sourcing methodology to the lab instructor for approval.
+
+2.  **Data Quality Assurance, Cleaning and Preparation**
+    *   Perform a deep audit of the dataset to identify and systematically address quality issues, including missing values, logical errors (e.g., negative fares), and extreme outliers.
+    *   Engineer new, insightful features such as `trip_duration`, `hour_of_day`, `day_of_week`, and `tip_percentage` to enhance analysis.
+
+3.  **Exploratory Data Analysis and Insight Generation**
+    *   **Temporal Analysis:** Identify hourly, daily, and seasonal demand patterns to pinpoint city-wide rush hours, airport run peaks, and off-peak periods.
+    *   **Geospatial Analysis:**
+        *   Map high-value pickup and drop-off zones using geospatial heatmaps.
+        *   Analyze trip flow between boroughs to identify the most lucrative routes and "hotspots."
+    *   **Financial & Behavioral Analysis:** Investigate the relationships between trip distance, duration, payment type, and tip percentage to confirm or debunk common driver assumptions (e.g., "Do credit card payments yield better tips?").
+
+4.  **Predictive Model Development**
+    *   Build, train, and validate the fare prediction regression model.
+    *   Build, train, and validate the high-tip classification model.
+    *   Perform hyperparameter tuning and use cross-validation techniques to optimize the performance and robustness of each model.
+    *   **Model Interpretation:** Analyze feature importance to understand why the models make certain predictions, extracting the key drivers behind fares and tips.
+
+5.  **Software Solution and Interface Development**
+    *   Design and develop a user-friendly web interface for the dashboard and integrate the trained machine learning models into the backend of the application to power the prediction features.
+    *   Embed key EDA visualizations into the dashboard to provide users with contextual insights.
+
+---
+
+## Approach
+
+1.  **Project Management & Version Control**
+    *   All code and documentation will be managed using Git and hosted on a platform like GitHub to ensure collaboration and version tracking.
+
+2.  **Data Preparation & Analysis**
+    *   **Libraries**
+        *   Pandas for data cleaning and transformation.
+        *   NumPy for numerical operation.
+        *   Matplotlib/Seaborn for static visualization.
+        *   GeoPandas for geospatial mapping.
+    *   **Geographical Analysis**
+        *   Join the trip data with public NYC Taxi Zone Shapefile.
+        *   Plot pickup density, average fares, and tip percentages by zone.
+        *   Provides location-based context that is highly relevant for drivers and decision making.
+
+3.  **Predictive Modeling**
+    Our modeling strategy is grounded in a systematic, iterative approach to ensure robustness and interpretability.
+    *   **Baseline Establishment**
+        *   Begin with a simple baseline model (e.g., **Linear Regression** for fare prediction or **Logistic Regression** for tip classification).
+        *   Serves as a benchmark to ensure any complex model provides a tangible improvement in performance.
+    *   **Advanced Modeling**
+        *   Progress to ensemble methods such as **Random Forest** and **XGBoost**, which are industry standards for tabular data.
+        *   Capture complex non-linear relationships (e.g., interaction between time of day and pickup location on fare price).
+    *   **Evaluation strategy**
+        *   **Fare Regression Model:** Use Root Mean Squared Error (RMSE) to measure prediction error in dollars, providing directly interpretable results.
+        *   **Tip Classification Model:** Focus on **F1-score** and **ROC-AUC score** to handle class imbalance (fewer high-tip trips) and evaluate model discrimination.
+    *   **Interpretability**
+        *   Employ techniques like **SHAP** (SHapley Additive exPlanations) or model feature importance plots.
+        *   Explain which factors (e.g., trip duration, pickup location) most influence predictions, moving beyond a "black box" model and providing actionable insights for drivers.
+
+4.  **Software Solution**
+    The interactive dashboard will be developed as a web application using Python frameworks.
+    *   **Frameworks:** We will use a lightweight framework such as **Streamlit** or **Flask** to build the application, allowing for rapid development of the interactive user interface.
+
+---
+
+## Deliverables
+
+The following deliverables will be produced as part of the project outcome:
+
+1.  **Cleaned and Processed Dataset**
+    *   A refined dataset in CSV format, created from the original source. This dataset will have had missing values handled, outliers treated, and new features engineered, making it ready for modeling.
+
+2.  **Exploratory Data Analysis (EDA) & Modeling Notebooks**
+    *   A set of well-documented Jupyter Notebooks that provide a complete, reproducible record of the project's workflow, including data cleaning, the full exploratory analysis, and the model development process.
+
+3.  **Predictive Machine Learning Models**
+    *   The final, serialized versions of the trained regression model (for fare prediction) and classification model (for tip prediction), saved as pickle files.
+    *   Documentation of each model's final performance metrics (RMSE for regression, F1-score and ROC-AUC for classification).
+
+4.  **User-Friendly Web Application**
+    *   A functional, standalone web application that serves as the primary user-facing deliverable.
+    *   Features will include:
+        *   An interactive form for users to input trip parameters (e.g., pickup/drop-off locations, time of day).
+        *   Real-time predictions for the estimated fare and the probability of a high tip.
+        *   A dashboard of key visualizations from the EDA that provide strategic insights.
+
+5.  **Final Project Report and Documentation**
+    *   A detailed written report covering background, scope, methodology, results, and conclusions.
+    *   A brief user guide for operating the web application.
+
+---
+
+## Assumptions
+
+To ensure the successful development and deployment of the NYC Yellow Taxi Fare and Analysis the following assumptions have been made:
+
+1.  **Data Representativeness Assumption**
+    *   The provided static dataset is assumed to be a sufficiently large and accurate sample that reflects the general operational patterns of the NYC taxi industry.
+
+2.  **Data Field Integrity Assumption**
+    *   It is assumed that the data fields are consistent and accurate. For instance, payment_type codes have a consistent meaning, and timestamps are recorded correctly, allowing for the reliable calculation of trip_duration.
+
+3.  **Independence of Trips Assumption**
+    *   Each record (trip) in the dataset is assumed to be an independent event, with no dependencies on other trips that could bias the model.
+
+4.  **Location Data Mapping Assumption**
+    *   We assume that the PULocationID and DOLocationID fields can be reliably and accurately mapped to meaningful geographical zones (e.g., boroughs, neighborhoods) using the publicly available NYC Taxi Zone lookup table.
+
+5.  **No Major Unseen Variables Assumption**
+    *   It is assumed that the primary factors influencing fares and tips (e.g., distance, time, location) are present in the dataset, and that there are no major hidden variables (e.g., city-wide events, weather) that significantly impact the outcomes.
+
+6.  **Consistency of Data Distribution Assumption**
+    *   The training and testing datasets are assumed to follow a similar distribution, ensuring that models trained on the training set can generalize effectively to unseen data.
+
+---
+
+## Project Plan & Timeline
+
+*   **Planning & Strategy**
+    *   Define scope and finalize SOW: **Week 9**
+    *   Set Up Project Repository: **Week 9**
+*   **Data Curation & Preprocessing**
+    *   Dataset Sourcing & Sampling Script: **Week 9 - 10**
+    *   Data Cleaning & Quality Assurance: **Week 10**
+    *   Feature Engineering: **Week 10**
+*   **Analysis & Modeling**
+    *   Exploratory Data Analysis: **Week 11**
+    *   Model Building (Baseline & Advanced): **Week 11 - 12**
+    *   Model Evaluation & Tuning: **Week 12**
+*   **Solution Development & Integration**
+    *   Dashboard UI/UX Design: **Week 12**
+    *   Backend Development & Model Integration: **Week 12 - 13**
+    *   Frontend Development & Visualization: **Week 13**
+*   **Finalization & Submission**
+    *   Final Report Writing: **Week 14**
+    *   Video Presentation Recording & Editing: **Week 14**
+    *   Final Submission Package: **Week 14**
+
+---
+
+## Project Team, Roles and Responsibilities
+
+| Member IT Number | Member Name | Member Role | Member Responsibilities |
+| :--- | :--- | :--- | :--- |
+| IT23288744 | Chamuditha H V C | Team Leader, <br> Solution Developer, <br> Data Analyst | - Coordinate team activities and ensure timely progress. <br> - Lead the initial data sourcing, sampling, and cleaning processes. <br> - Conduct foundational EDA (e.g., temporal, and univariate analysis). <br> - Contribute to documentation and report preparation. <br> - Oversee the final report compilation and ensure all deliverables are of high quality. |
+| IT23291782 | Hariswara S | Data Analyst, <br> Backend Developer | - Lead the advanced, in-depth EDA, focusing on geospatial analysis and financial patterns. <br> - Take primary responsibility for feature engineering, including the inflation adjustment. <br> - Develop the backend of the web application. <br> - Develop Initial predictive and classifier models. |
+| IT23385900 | Ranasinghe I V L | Machine Learning Engineer | - Lead the development, training, and hyperparameter tuning of both the fare prediction and tip classification models. <br> - Conduct rigorous model evaluation and comparison to select the best-performing algorithms. <br> - Analyze and interpret model results for the final report. <br> - Assist with the testing of the integrated models |
+| IT23232990 | Thennakoon S S H | Frontend Developer <br> QA Specialist | - Lead the design and development of the user interface for the interactive dashboard. <br> - Integrate the EDA visualizations into the frontend to create an insightful user experience. <br> - Take primary responsibility for Quality Assurance (QA), including testing the predictive models and the final web application for bugs and usability. <br> - Lead preparation of project documentation and user guide. |
\ No newline at end of file
diff --git a/plan.md b/plan.md
new file mode 100644
index 0000000..4b70428
--- /dev/null
+++ b/plan.md
@@ -0,0 +1,64 @@
+## Project Alignment Assessment
+
+Your project shows **strong alignment** with the requirements (estimated **75-85%**). Here's the breakdown:
+
+### ✅ **Fully Aligned (Meeting Requirements)**
+
+**1. Problem Definition & Business Goals [20%]** - STRONG
+- ✅ Clear client (NYC Taxi Drivers' Union)
+- ✅ Well-defined problem (data-driven insights for drivers)
+- ✅ Dataset approved (>100k rows from NYC TLC data, reduced to 97,139 after cleaning)
+- ✅ SOW document comprehensive
+
+**2. Data Selection & Preprocessing [20%]** - STRONG
+- ✅ Stratified sampling implemented (`datasampling.py`)
+- ✅ Comprehensive cleaning pipeline (`datacleaning.py`)
+- ✅ Quality assurance with verification (all checks PASS in `verification_report.md`)
+- ✅ Feature engineering (trip_duration_min, zone enrichment)
+- ✅ Documented cleaning rules and reports
+
+**3. Building & Evaluating Models [20%]** - MODERATE
+- ✅ Two models created (`fare_model.pkl`, `tip_model.pkl`)
+- ⚠️ **Need to verify:** Model documentation, evaluation metrics (RMSE, F1-score, ROC-AUC), hyperparameter tuning evidence
+- ⚠️ **Need to verify:** Model interpretability (SHAP/feature importance) as mentioned in SOW
+
+**4. Deploying Product [20%]** - MODERATE
+- ✅ Streamlit web application exists (`streamlit_app/app.py`)
+- ⚠️ **Need to verify:** Interactive prediction interface integration
+- ⚠️ **Need to verify:** EDA visualizations embedded in dashboard
+- ⚠️ **Missing:** Evidence of model predictions accessible through UI
+
+**5. Documentation [20%]** - PARTIAL
+- ✅ Cleaning reports, verification reports, data dictionary
+- ✅ README with project snapshot
+- ⚠️ **Missing:** Final project report
+- ⚠️ **Missing:** Video presentation (due Oct 6)
+- ⚠️ **Missing:** User guide for web application
+
+### ⚠️ **Critical Gaps to Address Before Submission**
+
+1. **EDA Documentation** - Need comprehensive Jupyter notebook showing temporal, geospatial, financial analysis (mentioned in SOW but needs verification in `Data Engineering.ipynb`)
+
+2. **Model Documentation** - Must document:
+   - Baseline vs advanced model comparison
+   - Performance metrics (RMSE for fare, F1/ROC-AUC for tips)
+   - Feature importance/SHAP analysis
+
+3. **Final Report** - Complete report following template with:
+   - Video link, repo link, deployment link on cover
+   - All sections from SOW
+
+4. **Video Presentation** - 10-minute demo (not yet created)
+
+5. **Source Code Packaging** - Consolidate all `.py` files for submission
+
+### 📊 **Scoring by Rubric Categories**
+
+Based on the marking grid:
+- **Problem definition**: 70-80% (clear but needs final report formalization)
+- **Data preparation**: 80-89% (excellent work, well-documented)
+- **Models**: 60-70% (models exist but documentation unclear)
+- **Deployment**: 60-70% (app exists but prediction integration unclear)
+- **Documentation**: 50-60% (technical docs good, final deliverables missing)
+
+**Immediate Priority**: Verify the Jupyter notebook contains full EDA, confirm model prediction UI works, and prepare final report template.
diff --git a/streamlit_app/app.py b/streamlit_app/app.py
index 9e86aa0..95c8293 100644
--- a/streamlit_app/app.py
+++ b/streamlit_app/app.py
@@ -8,7 +8,10 @@ import plotly.graph_objects as go
 import streamlit as st
 
 
-WORKSPACE_ROOT = "/Users/harish/FDM_EDA"
+# Determine the workspace root dynamically
+# Assumes the script is in streamlit_app and the data is in the parent directory
+SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
+WORKSPACE_ROOT = os.path.dirname(SCRIPT_DIR)
 CSV_PATH = os.path.join(WORKSPACE_ROOT, "NYC_YELLOW_TAXI_CLEAN.csv")
 PARQUET_PATH = os.path.join(WORKSPACE_ROOT, "NYC_YELLOW_TAXI_CLEAN.parquet")
 ZONES_GEOJSON_PATH = os.path.join(WORKSPACE_ROOT, "Docs", "taxi_zones.geojson")
